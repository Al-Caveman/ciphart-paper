\documentclass[twocolumn]{article}
\usepackage[margin=.7in]{geometry}
\usepackage[showisoZ=false]{datetime2}
\usepackage{url}
\usepackage{tabularx}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\newtheorem{security}{security interpretation}
\newtheorem{definition}{definition}
\newtheorem{theorem}{theorem}
\newtheorem{note}{note}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\DeclareMathOperator{\enc}{\mathtt{enc}}
\DeclareMathOperator{\dec}{\mathtt{dec}}
\DeclareMathOperator{\maxf}{max}
\DeclareMathOperator{\len}{len}
\DeclareMathOperator{\hash}{\mathtt{hash}}
\DeclareMathOperator{\rhash}{\mathtt{rhash}}
\DeclareMathOperator{\mhash}{\mathtt{mhash}}
\DeclareMathOperator{\argon}{\mathtt{argon2}}
\DeclareMathOperator{\ciphart}{\mathtt{ciphart}}
\DeclareMathOperator{\cost}{\mathtt{cost}}
\DeclareMathOperator{\henc}{\; HENC}
\DeclareMathOperator{\hhash}{\; HHASH}
\renewcommand{\contentsname}{paper's layout}
\makeatletter
\def\myrulefill{%
    \leavevmode\leaders\hrule%
    height .6ex width 1ex depth -0.4ex%
    \hfill\kern\z@%
}
\makeatother
\DTMsetdatestyle{iso}
\usepackage{cleveref} % must be loaded last
\begin{document}
\SetAlgorithmName{algorithm}{}{list of algorithms}
\SetInd{.15em}{1em}

\begin{center}
\Huge
\myrulefill\ ciphart \myrulefill\\
\LARGE
memory-hard key derivation \\
with easier measurable security\\
\normalsize
caveman\footnote{mail: toraboracaveman [at] protonmail [dot] com}\\
\footnotesize
\DTMnow\\
\rule{1\columnwidth}{2pt}
\end{center}

argon2\footnote{\url{https://github.com/P-H-C/phc-winner-argon2}} is mostly
nice, but trying to interpret its contribution to the protection against
password brute-forcing attacks remains more difficult than it should be.
this vagueness is a problem that is not limited to \emph{argon2}, but also
shared with every other key derivation function that i've known so far.

when one uses \emph{argon2}, his derived key will surely have superior
protection against password brute-forcing attacks, but by how much?  to
answer this, one would need to survey the industry that manufactures
application-specific integrated circuits (asics) to obtain a map between
\emph{time} and \emph{money}, in order to get an estimation on how much
would it cost the adversary to discover the password in a given time
window.

while the approach of surveying the asics industry is not wrong, it is
largely subjective, with expensive housekeeping, and practically leads the
user to rely on vague foundations to build his security on.  this vagueness
is not nice, and it would be better if we had an objective measure to
quantify the security of our memory-hard key derivation functions.

resolving this vagueness is not a mere luxury to have, but a necessity for
maximising survival, because it hinders the process of studying the
cost-value of memory-hard key derivation functions, which, effectively,
increases the risk of having a false sense of security.

so i propose \emph{ciphart} --- a memory-hard key derivation function with
a security contribution that is measured in a unit that i call
\emph{caveman's entropy bits}.  this unit is measured objectively and is
guaranteed to be true irrespective of whatever alien technology that the
adversary might have.

\texttt{libciphart}\footnote{\url{https://github.com/Al-Caveman/libciphart}}
is a library that implements \emph{ciphart} very closely to this paper,
without much fluff.  this should make integrating \emph{ciphart} into other
systems more convenient.

\texttt{ciphart}\footnote{\url{https://github.com/Al-Caveman/ciphart}} is
an application for encrypting and decrypting files that makes use of
\texttt{libciphart}.  this application is intended for use by end-users or
scripts, henceforth it has some fluff to treat mankind with dignity.

\tableofcontents
\noindent
\rule{1\columnwidth}{2pt}

\section{shannon's entropy}
we've got password $p$ with $H(p)$ many shannon's entropy bits worth of
information in it.  so what does this mean?

fundamentally, it means that, on average, we'd need to ask $H(p)$ many
perfect binary questions\footnote{one which, if answered, and on average,
gets the search space reduced in half.} in order to fully resolve all
ambiguities about $p$; i.e.  to fully get every bit of $p$.  

but people use it to do less orthodox things, such as quantifying the
amount of security $p$ has against, say, brute-forcing attacks.

say that we've got a $8V$ bit key $k \gets \hash(p \Vert s, 8V)$, derived
from password $p$, where $s$ is a salt.  say that the attacker has $s$ and
$k$ but wants to figure out $p$.  in this case, he will need to brute-force
the password space in order to find $p$ that gives $k$.  his cost is:
\begin{equation}\label{eq_cost_passbruteforce}
    2^{H(p)} \left(
        \cost(\hash) + \cost(\text{if } \hat k = k)
    \right)
\end{equation}

\begin{definition}
the security of a system is the cost of the cheapest method that can break
it.
\end{definition}

one way to estimate $\cost$ is to survey the asics industry.  by surveying
the asics industry to get an idea how much money it costs to get a given
key, or password, space brute-forced within a target time
frame\footnote{see the \emph{scrypt} paper for an example.}.  this has an
expensive housekeeping and is usually not possible to get any guarantees as
we don't know about state-of-art manufacturing secrets that adversaries may
have.  the \emph{scrypt} paper has an example of such attempt.

another way is to ignore anything that has no cryptographic guarantee.  so,
in (\ref{eq_cost_passbruteforce}), cryptography
guarantees\footnote{statistically by confidence earned through peer review
and attempts to break encryption algorithms.} that $2^{H(p)}$ many $\hash$
calls are performed and that many equality tests.  the $\hash$ call needs
to be done once, so let's give it a unit of time $1$.  the equality test
also needs to be called once, but since since it's so cheap it's easier to
just assume that its cost is free.  this way (\ref{eq_cost_passbruteforce})
becomes just:
\begin{equation}\label{eq_simplecost_passbruteforce}
    2^{H(p)} (1+0) = 2^{H(p)}
\end{equation}

further, for convenience, it seems that people report it in the $\log_2$
scale.  i.e. $\log_2 2^{H(p)} = H(p)$.  i think this is why people use
password entropy as a measure of its security.  not because it is the
quantity of security, but rather because its the quantity of
\emph{simplified} security.  

\section{caveman's entropy}
\subsection{recursive $\hash$}
if the $\hash$ function is replaced by an $N$-deep recursion over $\hash$,
like:
\[
    \begin{split}
        & \rhash(p \Vert s, 8V, N) \\
    ={} &  \hash(\hash(\ldots\hash(p \Vert s, 8V), \ldots, 8V), 8V)
    \end{split}
\]
then, if $\hash$ is not broken,  (\ref{eq_cost_passbruteforce}) becomes:
\begin{equation}\label{eq_cost_passbruteforce_N}
    2^{H(p)} \left(
        N\cost(\hash) + \cost(\text{if } \hat k = k)
    \right)
\end{equation}
and (\ref{eq_simplecost_passbruteforce}) becomes:
\begin{equation}\label{eq_simplecost_passbruteforce_N}
    \begin{split}
    2^{H(p)} (N+0) &= N2^{H(p)} \\
                  &= 2^{H(p) + \log_2 N}
    \end{split}
\end{equation}

at this point, thanks to cryptographic guarantees, there is absolutely no
security distinction between a password with shannon's $H(p) + \log_2 N$
entropy bits, and a password with just $H(p)$ entropy bits that made use of
the $N$-deep recursive calls of $\hash$.

shannon's entropy of $p$ remains $H(p)$, but thanks to the recursive calls
of $\hash$, that password will be as expensive as another password $\hat
p$, such that $H(\hat p) = H(p) + \log_2 N$.

i think it will be simpler if we introduce the function-dependent caveman's
entropy $C$ as a measure.  it goes like this:
\begin{equation}
    C\Big(p, \hash(\ldots)\Big) = H(p)
\end{equation}

\begin{equation}
    C\Big(\hat p, \hash(\ldots)\Big) = H(p) + \log_2 N
\end{equation}

\begin{equation}
    \begin{split}
        C\Big(p, \rhash(\ldots, N)\Big) &= H(p) + \log_2 N \\
                                &= H(\hat p) \\
    \end{split}
\end{equation}

security-wise, there is no distinction between the more complex password
$\hat p$, and the simpler password $p$ that used $\rhash(\ldots, N)$.  so i
really think we need to measure password security in $C$ instead of $H$.

\subsection{memory-hard $\hash$}
let $\mhash$ be like $\rhash$, except that it also requires $M$ many memory
bytes such that, as available memory is linearly reduced from $M$, penalty
in cpu time grows exponentially.  let $M$ be requested memory, $\hat M$ be
available memory, and $e(M - \hat M)$ be the exponential penalty value for
reduction in memory, where $e(0) = 1$.
\begin{equation}
    \begin{split}
        & \cost\Big(\mhash(p \Vert s, N, M)\Big) \\
    ={} & \cost\Big(\rhash(p \Vert s, N)\Big)^{e(\hat M - M)}
    \end{split}
\end{equation}

if $\hash$ in (\ref{eq_cost_passbruteforce}) is replaced by the $M$-bytes
memory-hardened $N$-deep recursion hash function $\mhash$, then
(\ref{eq_cost_passbruteforce}) becomes:
\begin{equation}\label{eq_cost_passbruteforce_NM}
    2^{H(p)} \left(
        N^{e(M-\hat M)}\cost(\hash) + \cost(\text{if } \hat k = k)
    \right)
\end{equation}
and (\ref{eq_simplecost_passbruteforce}) becomes:
\begin{equation}\label{eq_simplecost_passbruteforce_NM}
    \begin{split}
    2^{H(p)} (N^{e(M-\hat M)}+0) &= N^{e(M-\hat M)} 2^{H(p)} \\
                  &= 2^{H(p) + \log_2 N^{e(M-\hat M)}} \\
                  &= 2^{H(p) + e(M-\hat M)\log_2 N}
    \end{split}
\end{equation}
and caveman's entropy becomes:
\begin{equation}
    C\Big(p, \mhash(\ldots, N, M)\Big) = H(p) + e(M-\hat M)\log_2 N
\end{equation}

\subsection{implications}
let $p$ be a password with $H(p)$ shannon's entropy bits.  let $\hat p$ be
a more complex password with $H(p) + e(M-\hat M)\log_2 N$ shannon's entropy
bits, where $M$, $\hat M$ and $N$ are all positive numbers.

then caveman's entropy says that the following keys are information
theoretically indistinguishable for as long as only $p$ and $\hat p$ remain
unknown (everything else is known, such as the distribution from which $p$
and $\hat p$ was sampled), and for as long as $\hash$ is not broken:
\begin{itemize}
    \item $k \gets \mhash(p \Vert s, N, M)$
    \item $\hat k \gets \hash(\hat p \Vert s)$
\end{itemize}

in other words:
\begin{equation}
    C\Big(p, \mhash(\ldots, N, M)\Big) = H(\hat p)
\end{equation}

since the assumption that passwords are kept away from the adversary is
fundamental in a symmetric encryption context, i think it makes since that
we measure our security with memory-hard key derivation functions using the
caveman's entropy $C$.

from a security point of view, it will feel absolutely identical to as if
the password got injected with extra shannon's entropy bits.  no one can
tell the difference for as long as the fundamental assumption of hiding
passwords is honoured, as well as the hashing function $\hash$ is not
broken.

in other words, we can say, if password $p$ is unknown, and $\hash$ is not
broken, then we have injected into $p$ extra shannon's entropy bits.  this
lie will be only discovered after $p$ is revealed ---  call it caveman's
cat thought experiment.

if you think that it is impossible for this \emph{lie} to be \emph{truth}
under the secrecy of $p$, then i've done an even better job: proving that
cryptographically secure hashing functions do not exist.  likewise, same
can be trivially extended to: cryptographically symmetric ciphers do not
exist.

so you have to pick either one of two options:
\begin{enumerate}
    \item either accept that the lie is truth.  i.e. we injected shannon's
    entropy bits into $p$, for as long as only $p$ is not revealed.
    \item or, accept that cryptographically-secure hashing and
    symmetric-encryption functions functions do not exist.
\end{enumerate}

\begin{theorem}[the perfect lie]\label{theorem_perfect_lie}
when $p$ is secret and $\hash$ is not broken, then shannon's entropy $H$ of
the derived key equals caveman's entropy $C$.
\end{theorem}

i call \cref{theorem_perfect_lie} the \emph{perfect lie theorem} in a sense
that a perfect lie is indistinguishable from truth.

the reason this lie is appealing is because it simplifies our
quantification of the amount of security that we have gained by using a
given key derivation function.

without treating this lie as truth, our only hope would be surveying the
asics industry.  but with this lie, we have one more approach to get a feel
of the gained security quantity by just accepting caveman's entropy $C$ as
shannon's entropy $H$, and move on as if the lie is truth, and no one can
notice it.

we can also look at it from the perspective of \emph{occam's razor}.  i.e.
if two things are not distinguishable from one another, then assuming that
they are just the same thing is simpler than assuming otherwise.  since (1)
each assumption bit has a positive probability of error, (2) since assuming
that indistinguishable things are different than one another is more
complex (i.e. more assumption bits) than assuming not, and (3) since there
is no observable difference between the two things, therefore it
necessarily follows that our model's total error will be reduced if we
accept that the indistinguishable things are identical (i.e.  which is what
\cref{theorem_perfect_lie} says).

\section{ciphart}
\subsection{parameters}
\begin{tabularx}{\columnwidth}{lX}
    $\enc$ & encryption function.\\
    $p$ & password.\\
    $s$ & salt.\\
    $M$ & total memory in bytes.\\
    $L$ & number of memory lanes for concurrency.\\
    $T$ & number of tasks per lane segment.\\
    $B$ & minimum quantity of increased protection against password
            brute-forcing attacks in the unit of \emph{caveman's entropy
            bits}.\\
    $K$ & output key size in bytes.\\
\end{tabularx}

\subsection{internal variables}
\begin{tabularx}{\columnwidth}{lX}
    $\hash$ & hashing function.\\
    $C$         & $\gets \begin{cases}
                        64 \text{ bytes} & \text{if $\enc$ is
                                            \emph{xchacha20}}\\
                        16 \text{ bytes} & \text{if $\enc$ is \emph{aes}}\\
                        \ldots & \\
                     \end{cases}$\\
                & this to reflect the block size of the encryption
                    algorithm that implements $\enc$.\\
    $V$ & $\gets \begin{cases}
                        32 \text{ bytes} & \text{if $\enc$ is
                                            \emph{xchacha20}}\\
                        16 \text{ bytes} & \text{if $\enc$ is
                            \emph{aes-128}}\\
                        32 \text{ bytes} & \text{if $\enc$ is
                            \emph{aes-256}}\\
                        \ldots & \\
                     \end{cases}$\\
                & this is the size of the encryption key that's used to
                    solve \emph{ciphart}'s tasks.  this is different than
                    the $\enc$-independent $K$ which is
                    possibly used by other encryption algorithms in later
                    stages\footnote{at the expense of losing the meaning of
                    \emph{caveman's entropy bits}.}.\\
    $\hat T$    & $\gets \maxf(\lceil V C^{-1}\rceil, T)$.  this
                    is to ensure that we have enough encrypted bytes for
                    new keys.\\
    $\hat T$    & $\gets \hat T - (\hat T \bmod 2) + 2$.  this is to ensure
                    that there is an even number of tasks in a segment.
                    why?  because we need a buffer for storing the
                    clear-text and another for storing the output
                    cipher-text.\\
    $\hat M$    & $\gets M - (M \bmod C\hat TL) + C\hat TL$.  this is to
                    ensure that it is in multiples of $C\hat TL$.  why?  so
                    that all segments are of equal lengths in order to
                    simplify \emph{ciphart}'s logic.  e.g. it wouldn't be
                    nice if the last segments were of unequal sizes.\\
    $G$         & $\gets \hat MC^{-1}\hat T^{-1}L^{-1}$.  total number of
                    segments per lane.\\
    $N$    & $\gets 0$.  actual number of times $\enc$ is called,
                    where $\hat N \ge 2^B$.\\
    $m_i$       & $C$-bytes memory for $i^{th}$ task in the $\hat M$-bytes
                    pad.\\
    $n_l$       & $\gets lG\hat T$.  nonce variable for $l^{th}$ lane with
                    at least $64$ bits.\\
    $f$         & $\gets 0$.  a flag indicating whether the $\hat M$-bytes
                    pad is filled.\\
    $v$         & $\gets *\hash(p \mathbin\Vert s, V)$.  a pointer to the
                    first byte where $V$-bytes key is stored.\\
\end{tabularx}

\subsection{output}
\begin{tabularx}{\columnwidth}{lX}
$k$ & $K$-bytes key.\\
$\hat B$ & actual quantity of increased security against password
            brute-forcing attacks in the unit of \emph{caveman's entropy
            bits}, where $\hat B \ge B$.\\
\end{tabularx}

\subsection{steps}
steps of \emph{ciphart} is shown in \cref{alg_ciphart}.  this corresponds
to \emph{argon2d}.  adding a \emph{ciphart-i} variant is a trivial matter,
i just didn't do it yet because my threat model currently doesn't benefit
from a password independent variant.

\begin{algorithm}[tbh]
\While{$1$}{
    \For{$g=0, 1, \ldots, G-1$}{
        \For{$l=0, 1, \ldots, L-1$}{\label{ciphart_lanes}
            \For{$t=0, 1, \ldots, T-1$}{
                $i \gets gLT + lT + t$\;
                \uIf{$t < T - 1$}{
                    $j \gets i + 1$\;
                }\ElseIf{$t = T - 1$}{
                    $j \gets i - T + 1$\;
                }
                $m_j \gets \enc(m_i, n_l, v)$\;
                $n_l \gets n_l + 1$\;
                \uIf{$f = 0$}{
                    $v \gets m_j \bmod (gLTC + tC - V)$\;
                    \If{$v \ge gLTC - V$}{
                        $v \gets v + lTC$\;
                    }
                }\Else{
                    $v \gets m_j \bmod (\hat M - LTC + tC - V)$\;
                    \uIf{$v \ge gLTC + tC - V$}{
                        $v \gets v + LTC$\;
                    }\ElseIf{$v \ge gLTC - V$}{
                        $v \gets v + lTC$\;
                    }
                }
            }
        }
        $N \gets N + LT$\;
        \If{$N \ge 2^B$}{
            $g_{\text{last}} \gets g$\;
            \textbf{go to} \cref{ciphart_out}\;
        }
    }
    $f \gets 1$\;
}
$i \gets g_{\text{last}}LT$\;\label{ciphart_out}
$k \gets \hash(m_{i+0T} \Vert m_{i+1T} \Vert \ldots \Vert m_{i+(L-1)T}, K)$\;
$\hat B \gets log_2 N$\;
\Return{$k$, $\hat B$}
\caption{ciphart}
\label{alg_ciphart}
\end{algorithm}

\section{parallelism}
since iterations of the loop in \cref{ciphart_lanes} in \cref{alg_ciphart}
are fully independent of one other, they can quite happily utilise $L$ cpu
cores, specially when segment sizes, $T$, are larger.

\section{memory-hardness}
\begin{proof}
    \cref{alg_ciphart} is just a variation of \emph{argon2d}, except that
    it uses an encryption function, $\enc$, instead of a hashing functionn.
    so if \emph{argon2d} is memory-hard, then so is \emph{ciphart}.
\end{proof}

\section{security interpretation}
\begin{note}
    i assume that the decryption part of the encryption algorithm $\enc$
    costs the same as the encryption.  this is true for algorithms such as
    \emph{xchacha20}.  and in cases where it is not true, such as with aes,
    \emph{ciphart} can simply encrypt using the decryption function.  this
    way we guarantee that the cost are identical between \emph{ciphart}'s
    encryption, and the cipher-text decryption that the adversary does to
    test a given key.
\end{note}

let's say that we used block encryption function $\enc$ and a key $v \gets
\hash(p \Vert s, V)$ to encrypt some clear-text into a sequence of $C$-byte
cipher-text blocks $m_0, m_1, \ldots$.  let's say that the adversary got
those $m_0, m_1, \ldots$.

adversary's goal is to decrypt those cipher-text blocks back into the
original clear-text.  so what options does he have?

\subsection{key brute-forcing}
brute-force the $V$-bytes key space.  in order to get a probability of $1$
of finding the key $v$, the adversary would need to evaluate $2^{8V}$ many
keys\footnote{assuming that each byte is $8$ bits.}.

this works by having the adversary repeatedly decrypting $m_0$ with $\enc$,
each time using a new key among
\begin{itemize}
    \item $\hat v_0 \gets \texttt{0x00\ldots 0}$,
    \item $\hat v_1 \gets \texttt{0x00\ldots 1}$,
    \item $\vdots$
    \item $\hat v_{2^{8V-1}} \gets \texttt{0xff\ldots f}$,
\end{itemize}
until the adversary finds a key that manages to decrypt $m_0$.

the adversary could be extremely lucky and have $v_0$ manage to decrypt
$m_0$, hence needing to call $\enc$ only once.  

or he might be extremely unlucky and need to keep trying until
$v_{2^{8V}-1}$ manages to do it, hence needing to call $\enc$ for $2^{8V}$
many times.

usually it's sometime in between.  asymptotically  n on average, the
adversary would need to call $\enc$ for $2^{8V}/2$ many times.

but in order to guarantee finding $v$, the brute-forcing process would need
to run $2^{8V}$ many evaluations, hence calling $\enc$ for $2^{8V}$ many
times.

that said, the adversary would be fossilised long before his application
completes.  e.g.  since $8V = 256$ is common for ciphers nowadays, on
average while considering the lucky and the unlucky cases, it would take my
laptop $4.28\times10^{58}$ centuries to just increment a counter for
$2^{256}$ many times.  so if the adversary's best hope is to brute-force
keys, our system has reached maximum security.

\begin{security}
your protection against key brute-forcing attacks with key brute-forcing is
$2^{8V} \cost(\enc)$, where $\cost(\enc)$ is the cost of executing $\enc$ a
single time.  

this is usually called $8V$ \emph{entropy bits}.  but for the purpose of
helping later sections, i think it's better to call it $8V$ \emph{entropy
bits from the viewing angle of $\enc$}, or, for short:
\[
    8V \henc
\]
\end{security}

\begin{definition}
$\henc$ is entropy bits from the viewing angle of $\enc$.
\end{definition}

$\henc$  is specific only to $\enc$'s algorithm, so must hold with whatever
alien technology that the adversary may have, for as long as $\enc$, as an
algorithm, has no cryptanalysis.  if there is any cryptanalysis, we'll have
to subtract bits from $8V$, e.g. $8V
- z \henc$, where $z$ is number of reduced bits due to cryptanalysis.

\subsection{normal password brute-forcing}
brute-force the $H(p)$ bits password space.  where $H(p)$ is the amount of
entropy bits in $p$.  in order to get a probability of $1$ of finding the
password $p$, the adversary would need to evaluate $2^{H(p)}$ many
keys\footnote{the adversary does not know $p$, obviously, but he knows the
process that the user used to generate $p$, henceforth he knows $H(p)$.}.

this works by having the adversary repeatedly decrypting $m_0$ with $\enc$,
each time using a new key among:
\begin{itemize}
    \item $\hat v_0 \gets \hash(\hat p_0 \Vert s, V)$,
    \item $\hat v_1 \gets \hash(\hat p_1 \Vert s, V)$,
    \item $\vdots$
    \item $\hat v_{2^{H(p)}-1} \gets \hash(\hat p_{2^{H(p)}-1} \Vert s,
    V)$,
\end{itemize}
until the adversary finds a key that manages to decrypt $m_0$.

\begin{security}
your protection against password brute-forcing attacks with normal hashed
passwords is $2^{H(p)} \cost(\hash) + 2^{H(p)} \cost(\enc)$.  the latter
$\enc$ calls are due to trying to decrypt $m_0$ at every attempt.

this is usually called $H(p)$ \emph{entropy bits}.  but for the purpose of
this paper, i think it's better to be more specific.  from the viewing
angle of $\enc$, we get the entropy:
\[
    H(p) \henc
\]
and from the viewing angle of $\hash$, we get the entropy:
\[
    H(p) \hhash
\]
this may seem silly as it is too obvious, but i think it helps me to
communicate my thoughts in later sections.
\end{security}

\begin{definition}
$\hhash$ is entropy bits from the viewing angle of  $\hash$.
\end{definition}

\subsection{with \emph{argon2}}
adversary evaluates keys from:
\begin{itemize}
    \item $\hat v_0 \gets \argon(\hat p_0, N, M, \ldots)$,
    \item $\hat v_1 \gets \argon(\hat p_1, N, M, \ldots)$,
    \item $\vdots$
    \item $\hat v_{2^{H(p)}-1} \gets \argon(\hat p_{2^{H(p)}-1}, N, M,
    \ldots)$,
\end{itemize}

for every \emph{argon2} call, $\hash$ is called for $N$ many times if there
is $M$ bytes of memory.  so, from the viewing angle of $\hash$, we get:
\begin{itemize}
    \item $\hat v_0 \gets \hash(\hat p_0 \Vert s_0, V)$,
    \item $\hat v_1 \gets \hash(\hat p_1 \Vert s_1, V)$,
    \item $\vdots$
    \item $\hat v_{N2^{H(p)}-1} \gets \hash(\hat p_{N2^{H(p)}-1}
    \Vert s_{N2^{H(p)}-1}, V)$,
\end{itemize}

if an adversary lacks $M$ bytes, he can still compute $\argon(p, N, M,
\ldots)$, but at the expense of needing exponentially more cpu time as his
memory is linearly reduced.

\begin{security}
your protection against password brute-forcing attacks under the
\emph{argon2} protection is:
\begin{alignat*}{2}
        & N 2^{H(p)} \cost(\hash)          && + 2^{H(p)} \cost(\enc) \\
    ={} & 2^{H(p) + \log_2 N} \cost(\hash) && + 2^{H(p)} \cost(\enc) \\
\end{alignat*}
from the viewing angle of $\enc$ we get the entropy:
\[
    H(p) \henc
\]
while from the viewing angle of $\hash$ we get the entropy:
\[
    H(p) + \log_2 N \hhash
\]
\end{security}

so which one to pick?  i think people so far just pick $H(p) \henc$ to
reflect password's entropy, and seem to not pick $H(p) + \log_2 N \hhash$
as they don't seem to consider it entropy.  but i have two disagreements
with people:
\begin{itemize}
    \item i think not accepting that $H(p) + \log_2 N \hhash$ is entropy is
    needlessly limiting.  because i think $H(p) + \log_2 N \hhash$ is
    entropy as much as $H(p) \henc$ is entropy; it's just that they are
    measured from different viewing angles:  former is measured from the
    $\hash$ viewing angle, while the latter is measured from the $\enc$
    viewing angle.

    i don't see any reason why any of them is more true than the other.  i
    think that both of them are entropies, but of different units.

    \item why do people only pick either one of them?  it's technically
    false my view.  in my view truth is:  we're just dealing with two
    entropies measured in different units.  so i think truth is that we
    have the following number of entropy bits:
    \begin{alignat*}{2}
            & H(p)              && \henc \\
        +{} & H(p) + \log_2 N   && \hhash 
    \end{alignat*}
    which obviously looks a bit ugly, since we cannot sum them due to the
    terms having different units, which also gives our brain a hard time to
    get a feeling of what that even means.
\end{itemize}

so what's the solution here to this ugliness?  should we ignore $H(p)\henc
+ H(p)+\log_2N\hhash$ as an entropy measure that quantifies the security of
our protection against password brute-forcing, as people currently do, and
measure it only in terms of the computational cost by surveying the
industry of asics in order to find a map between
time and money?

my answer to the questions above is:  
\begin{itemize}
    \item no.  the right approach is to just admit that \emph{argon2}'s
    approach is dragging us into the situation where we end up with two
    entropies measured in different units.
    \item \emph{argon2}'s security contribution is measurable as entropy,
    except that it is ugly since it is made of two entropies in distinct
    units.  if we ignore this, we won't solve the problem, but end up
    stashing the dirts under the carpet.
    \item of course, we are always free to also survey the industry of
    asics to derive time-money maps, but this doesn't have to be our only
    approach to quantify our security gain.
\end{itemize}

\subsection{with \emph{ciphart}}
adversary evaluates keys from:
\begin{itemize}
    \item $\hat v_0 \gets \ciphart(\hat p_0, B, M, \ldots)$,
    \item $\hat v_1 \gets \ciphart(\hat p_1, B, M, \ldots)$,
    \item $\vdots$
    \item $\hat v_{2^{H(p)}-1} \gets \ciphart(\hat p_{2^{H(p)}-1}, B, M,
    \ldots)$,
\end{itemize}

mostly similar to $\argon$.  differences related to this section is that
$\ciphart$ calls $\enc$ instead of $\hash$, and specifies $B$ instead of
$N$, where $B \approx \log_2 N$.  similar exponential time penalty applies
with memory less than $M$.

\begin{security}
your protection against password brute-forcing attacks under the
\emph{ciphart} protection approach is:
\begin{align*}
        & \left(2^{H(p)} + 2^{\hat B}\right) \cost(\enc) + 2^{H(p)}
            \cost(\enc) \\
    ={} & \left(2^{H(p)} + 2^{\hat B} + 2^{H(p)}\right) \cost(\enc) \\
    ={} & \left(2\times2^{H(p)} + 2^{\hat B}\right) \cost(\enc) \\
    ={} & \left(2^{H(p) + \log_2 2} + 2^{\hat B}\right) \cost(\enc) \\
    ={} & \left(2^{H(p) + 1} + 2^{\hat B}\right) \cost(\enc)
\end{align*}
from the viewing angle of $\enc$ we get the entropy:
\[
    H(p) + 1 + \hat B \henc
\]
\end{security}

and there is no other viewing angle than $\enc$ since only $\enc$ is used!
as a result our brain can easily interpret it.  

plus, if we wish to study the industry of asics to obtain time-money maps,
our job will be much easier as we can simply look at the cost of asics that
are already implemented for $\enc$\footnote{e.g. if $\enc$ is a popular
algorithm, such as aes-256, then we can get more specific data from
manufacturers, ultimately giving us a more accurate time-money maps.  but
when $\enc$ is not popular, we may need to do rougher calculations based on
the expected asics area as done in the \emph{scrypt} paper.}.

\section{summary}

\end{document}
