\documentclass[twocolumn]{article}
\usepackage[margin=.7in]{geometry}
\usepackage[showisoZ=false]{datetime2}
\usepackage{url}
\usepackage{tabularx}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\newtheorem{security}{security interpretation}
\newtheorem{definition}{definition}
\newtheorem{note}{note}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\DeclareMathOperator{\enc}{\mathtt{enc}}
\DeclareMathOperator{\maxf}{max}
\DeclareMathOperator{\len}{len}
\DeclareMathOperator{\hash}{\mathtt{hash}}
\DeclareMathOperator{\argon}{\mathtt{argon2}}
\DeclareMathOperator{\ciphart}{\mathtt{ciphart}}
\DeclareMathOperator{\cost}{cost}
\DeclareMathOperator{\henc}{\; HENC}
\DeclareMathOperator{\hhash}{\; HHASH}
\renewcommand{\contentsname}{paper's layout}
\makeatletter
\def\myrulefill{%
    \leavevmode\leaders\hrule%
    height .6ex width 1ex depth -0.4ex%
    \hfill\kern\z@%
}
\makeatother
\DTMsetdatestyle{iso}
\usepackage{cleveref} % must be loaded last
\begin{document}
\SetAlgorithmName{algorithm}{}{list of algorithms}
\SetInd{.15em}{1em}

\begin{center}
\Huge
\myrulefill\ ciphart \myrulefill\\
\LARGE
memory-hard key derivation \\
with easier measurable security\\
\normalsize
caveman\footnote{mail: toraboracaveman [at] protonmail [dot] com}\\
\footnotesize
\DTMnow\\
\rule{1\columnwidth}{2pt}
\end{center}

argon2\footnote{\url{https://github.com/P-H-C/phc-winner-argon2}} is mostly
nice, but trying to interpret its contribution to the protection against
password brute-forcing attacks remains more difficult than it should be.
this vagueness is a problem that is not limited to \emph{argon2}, but also
shared with every other key derivation function that i've known so far.

when one uses \emph{argon2}, his derived key will surely have superior
protection against password brute-forcing attacks, but by how much?  to
answer this, one would need to survey the industry that manufactures
application-specific integrated circuits (asics) to obtain a map between
\emph{time} and \emph{money}, in order to get an estimation on how much
would it cost the adversary to discover the password in a given time
window.

while the approach of surveying the asics industry is not wrong, it is
largely subjective, with expensive housekeeping, and practically leads the
user to rely on vague foundations to build his security on.  this vagueness
is not nice, and it would be better if we had an objective measure to
quantify the security of our memory-hard key derivation functions.

resolving this vagueness is not a mere luxury to have, but a necessity for
maximising survival, because it hinders the process of studying the
cost-value of memory-hard key derivation functions, which, effectively,
increases the risk of having a false sense of security.

so i propose \emph{ciphart} --- a memory-hard key derivation function with
a security contribution that is measured in a unit that i call
\emph{caveman's entropy bits}.  this unit is measured objectively and is
guaranteed to be true irrespective of whatever alien technology that the
adversary might have.

\texttt{libciphart}\footnote{\url{https://github.com/Al-Caveman/libciphart}}
is a library that implements \emph{ciphart} very closely to this paper,
without much fluff.  this should make integrating \emph{ciphart} into other
systems more convenient.

\texttt{ciphart}\footnote{\url{https://github.com/Al-Caveman/ciphart}} is
an application for encrypting and decrypting files that makes use of
\texttt{libciphart}.  this application is intended for use by end-users or
scripts, henceforth it has some fluff to treat mankind with dignity.

\tableofcontents
\noindent
\rule{1\columnwidth}{2pt}

\section{shannon's entropy}
we've got password $p$ with $H(p)$ many shannon's entropy bits worth of
information in it.  which means that, on average, we'd need to ask $H(p)$
many perfect binary questions in order to fully resolve all ambiguities
about $p$; i.e.  to fully get every bit of $p$.  what is a perfect
question? one which, if answered, gets the search space reduced in half on
average.

\section{caveman's entropy}

\section{ciphart}
\subsection{parameters}
\begin{tabularx}{\columnwidth}{lX}
    $\enc$ & encryption function.\\
    $p$ & password.\\
    $s$ & salt.\\
    $M$ & total memory in bytes.\\
    $L$ & number of memory lanes for concurrency.\\
    $T$ & number of tasks per lane segment.\\
    $B$ & minimum quantity of increased protection against password
            brute-forcing attacks in the unit of \emph{caveman's entropy
            bits}.\\
    $K$ & output key size in bytes.\\
\end{tabularx}

\subsection{internal variables}
\begin{tabularx}{\columnwidth}{lX}
    $\hash$ & hashing function.\\
    $C$         & $\gets \begin{cases}
                        64 \text{ bytes} & \text{if $\enc$ is
                                            \emph{xchacha20}}\\
                        16 \text{ bytes} & \text{if $\enc$ is \emph{aes}}\\
                        \ldots & \\
                     \end{cases}$\\
                & this to reflect the block size of the encryption
                    algorithm that implements $\enc$.\\
    $V$ & $\gets \begin{cases}
                        32 \text{ bytes} & \text{if $\enc$ is
                                            \emph{xchacha20}}\\
                        16 \text{ bytes} & \text{if $\enc$ is
                            \emph{aes-128}}\\
                        32 \text{ bytes} & \text{if $\enc$ is
                            \emph{aes-256}}\\
                        \ldots & \\
                     \end{cases}$\\
                & this is the size of the encryption key that's used to
                    solve \emph{ciphart}'s tasks.  this is different than
                    the $\enc$-independent $K$ which is
                    possibly used by other encryption algorithms in later
                    stages\footnote{at the expense of losing the meaning of
                    \emph{caveman's entropy bits}.}.\\
    $\hat T$    & $\gets \maxf(\lceil V C^{-1}\rceil, T)$.  this
                    is to ensure that we have enough encrypted bytes for
                    new keys.\\
    $\hat T$    & $\gets \hat T - (\hat T \bmod 2) + 2$.  this is to ensure
                    that there is an even number of tasks in a segment.
                    why?  because we need a buffer for storing the
                    clear-text and another for storing the output
                    cipher-text.\\
    $\hat M$    & $\gets M - (M \bmod C\hat TL) + C\hat TL$.  this is to
                    ensure that it is in multiples of $C\hat TL$.  why?  so
                    that all segments are of equal lengths in order to
                    simplify \emph{ciphart}'s logic.  e.g. it wouldn't be
                    nice if the last segments were of unequal sizes.\\
    $G$         & $\gets \hat MC^{-1}\hat T^{-1}L^{-1}$.  total number of
                    segments per lane.\\
    $N$    & $\gets 0$.  actual number of times $\enc$ is called,
                    where $\hat N \ge 2^B$.\\
    $m_i$       & $C$-bytes memory for $i^{th}$ task in the $\hat M$-bytes
                    pad.\\
    $n_l$       & $\gets lG\hat T$.  nonce variable for $l^{th}$ lane with
                    at least $64$ bits.\\
    $f$         & $\gets 0$.  a flag indicating whether the $\hat M$-bytes
                    pad is filled.\\
    $v$         & $\gets *\hash(p \mathbin\Vert s, V)$.  a pointer to the
                    first byte where $V$-bytes key is stored.\\
\end{tabularx}

\subsection{output}
\begin{tabularx}{\columnwidth}{lX}
$k$ & $K$-bytes key.\\
$\hat B$ & actual quantity of increased security against password
            brute-forcing attacks in the unit of \emph{caveman's entropy
            bits}, where $\hat B \ge B$.\\
\end{tabularx}

\subsection{steps}
steps of \emph{ciphart} is shown in \cref{alg_ciphart}.  this corresponds
to \emph{argon2d}.  adding a \emph{ciphart-i} variant is a trivial matter,
i just didn't do it yet because my threat model currently doesn't benefit
from a password independent variant.

\begin{algorithm}[tbh]
\While{$1$}{
    \For{$g=0, 1, \ldots, G-1$}{
        \For{$l=0, 1, \ldots, L-1$}{\label{ciphart_lanes}
            \For{$t=0, 1, \ldots, T-1$}{
                $i \gets gLT + lT + t$\;
                \uIf{$t < T - 1$}{
                    $j \gets i + 1$\;
                }\ElseIf{$t = T - 1$}{
                    $j \gets i - T + 1$\;
                }
                $m_j \gets \enc(m_i, n_l, v)$\;
                $n_l \gets n_l + 1$\;
                \uIf{$f = 0$}{
                    $v \gets m_j \bmod (gLTC + tC - V)$\;
                    \If{$v \ge gLTC - V$}{
                        $v \gets v + lTC$\;
                    }
                }\Else{
                    $v \gets m_j \bmod (\hat M - LTC + tC - V)$\;
                    \uIf{$v \ge gLTC + tC - V$}{
                        $v \gets v + LTC$\;
                    }\ElseIf{$v \ge gLTC - V$}{
                        $v \gets v + lTC$\;
                    }
                }
            }
        }
        $N \gets N + LT$\;
        \If{$N \ge 2^B$}{
            $g_{\text{last}} \gets g$\;
            \textbf{go to} \cref{ciphart_out}\;
        }
    }
    $f \gets 1$\;
}
$i \gets g_{\text{last}}LT$\;\label{ciphart_out}
$k \gets \hash(m_{i+0T} \Vert m_{i+1T} \Vert \ldots \Vert m_{i+(L-1)T}, K)$\;
$\hat B \gets log_2 N$\;
\Return{$k$, $\hat B$}
\caption{ciphart}
\label{alg_ciphart}
\end{algorithm}

\section{parallelism}
since iterations of the loop in \cref{ciphart_lanes} in \cref{alg_ciphart}
are fully independent of one other, they can quite happily utilise $L$ cpu
cores, specially when segment sizes, $T$, are larger.

\section{memory-hardness}
\begin{proof}
    \cref{alg_ciphart} is just a variation of \emph{argon2d}, except that
    it uses an encryption function, $\enc$, instead of a hashing functionn.
    so if \emph{argon2d} is memory-hard, then so is \emph{ciphart}.
\end{proof}

\section{security interpretation}
\begin{note}
    i assume that the decryption part of the encryption algorithm $\enc$
    costs the same as the encryption.  this is true for algorithms such as
    \emph{xchacha20}.  and in cases where it is not true, such as with aes,
    \emph{ciphart} can simply encrypt using the decryption function.  this
    way we guarantee that the cost are identical between \emph{ciphart}'s
    encryption, and the cipher-text decryption that the adversary does to
    test a given key.
\end{note}

let's say that we used block encryption function $\enc$ and a key $v \gets
\hash(p \Vert s, V)$ to encrypt some clear-text into a sequence of $C$-byte
cipher-text blocks $m_0, m_1, \ldots$.  let's say that the adversary got
those $m_0, m_1, \ldots$.

adversary's goal is to decrypt those cipher-text blocks back into the
original clear-text.  so what options does he have?

\subsection{key brute-forcing}
brute-force the $V$-bytes key space.  in order to get a probability of $1$
of finding the key $v$, the adversary would need to evaluate $2^{8V}$ many
keys\footnote{assuming that each byte is $8$ bits.}.

this works by having the adversary repeatedly decrypting $m_0$ with $\enc$,
each time using a new key among
\begin{itemize}
    \item $\hat v_0 \gets \texttt{0x00\ldots 0}$,
    \item $\hat v_1 \gets \texttt{0x00\ldots 1}$,
    \item $\vdots$
    \item $\hat v_{2^{8V-1}} \gets \texttt{0xff\ldots f}$,
\end{itemize}
until the adversary finds a key that manages to decrypt $m_0$.

the adversary could be extremely lucky and have $v_0$ manage to decrypt
$m_0$, hence needing to call $\enc$ only once.  

or he might be extremely unlucky and need to keep trying until
$v_{2^{8V}-1}$ manages to do it, hence needing to call $\enc$ for $2^{8V}$
many times.

usually it's sometime in between.  asymptotically  n on average, the
adversary would need to call $\enc$ for $2^{8V}/2$ many times.

but in order to guarantee finding $v$, the brute-forcing process would need
to run $2^{8V}$ many evaluations, hence calling $\enc$ for $2^{8V}$ many
times.

that said, the adversary would be fossilised long before his application
completes.  e.g.  since $8V = 256$ is common for ciphers nowadays, on
average while considering the lucky and the unlucky cases, it would take my
laptop $4.28\times10^{58}$ centuries to just increment a counter for
$2^{256}$ many times.  so if the adversary's best hope is to brute-force
keys, our system has reached maximum security.

\begin{security}
your protection against key brute-forcing attacks with key brute-forcing is
$2^{8V} \cost(\enc)$, where $\cost(\enc)$ is the cost of executing $\enc$ a
single time.  

this is usually called $8V$ \emph{entropy bits}.  but for the purpose of
helping later sections, i think it's better to call it $8V$ \emph{entropy
bits from the viewing angle of $\enc$}, or, for short:
\[
    8V \henc
\]
\end{security}

\begin{definition}
$\henc$ is entropy bits from the viewing angle of $\enc$.
\end{definition}

$\henc$  is specific only to $\enc$'s algorithm, so must hold with whatever
alien technology that the adversary may have, for as long as $\enc$, as an
algorithm, has no cryptanalysis.  if there is any cryptanalysis, we'll have
to subtract bits from $8V$, e.g. $8V
- z \henc$, where $z$ is number of reduced bits due to cryptanalysis.

\subsection{normal password brute-forcing}
brute-force the $H(p)$ bits password space.  where $H(p)$ is the amount of
entropy bits in $p$.  in order to get a probability of $1$ of finding the
password $p$, the adversary would need to evaluate $2^{H(p)}$ many
keys\footnote{the adversary does not know $p$, obviously, but he knows the
process that the user used to generate $p$, henceforth he knows $H(p)$.}.

this works by having the adversary repeatedly decrypting $m_0$ with $\enc$,
each time using a new key among:
\begin{itemize}
    \item $\hat v_0 \gets \hash(\hat p_0 \Vert s, V)$,
    \item $\hat v_1 \gets \hash(\hat p_1 \Vert s, V)$,
    \item $\vdots$
    \item $\hat v_{2^{H(p)}-1} \gets \hash(\hat p_{2^{H(p)}-1} \Vert s,
    V)$,
\end{itemize}
until the adversary finds a key that manages to decrypt $m_0$.

\begin{security}
your protection against password brute-forcing attacks with normal hashed
passwords is $2^{H(p)} \cost(\hash) + 2^{H(p)} \cost(\enc)$.  the latter
$\enc$ calls are due to trying to decrypt $m_0$ at every attempt.

this is usually called $H(p)$ \emph{entropy bits}.  but for the purpose of
this paper, i think it's better to be more specific.  from the viewing
angle of $\enc$, we get the entropy:
\[
    H(p) \henc
\]
and from the viewing angle of $\hash$, we get the entropy:
\[
    H(p) \hhash
\]
this may seem silly as it is too obvious, but i think it helps me to
communicate my thoughts in later sections.
\end{security}

\begin{definition}
$\hhash$ is entropy bits from the viewing angle of  $\hash$.
\end{definition}

\subsection{with \emph{argon2}}
adversary evaluates keys from:
\begin{itemize}
    \item $\hat v_0 \gets \argon(\hat p_0, N, M, \ldots)$,
    \item $\hat v_1 \gets \argon(\hat p_1, N, M, \ldots)$,
    \item $\vdots$
    \item $\hat v_{2^{H(p)}-1} \gets \argon(\hat p_{2^{H(p)}-1}, N, M,
    \ldots)$,
\end{itemize}

for every \emph{argon2} call, $\hash$ is called for $N$ many times if there
is $M$ bytes of memory.  so, from the viewing angle of $\hash$, we get:
\begin{itemize}
    \item $\hat v_0 \gets \hash(\hat p_0 \Vert s_0, V)$,
    \item $\hat v_1 \gets \hash(\hat p_1 \Vert s_1, V)$,
    \item $\vdots$
    \item $\hat v_{N2^{H(p)}-1} \gets \hash(\hat p_{N2^{H(p)}-1}
    \Vert s_{N2^{H(p)}-1}, V)$,
\end{itemize}

if an adversary lacks $M$ bytes, he can still compute $\argon(p, N, M,
\ldots)$, but at the expense of needing exponentially more cpu time as his
memory is linearly reduced.

\begin{security}
your protection against password brute-forcing attacks under the
\emph{argon2} protection is:
\begin{alignat*}{2}
        & N 2^{H(p)} \cost(\hash)          && + 2^{H(p)} \cost(\enc) \\
    ={} & 2^{H(p) + \log_2 N} \cost(\hash) && + 2^{H(p)} \cost(\enc) \\
\end{alignat*}
from the viewing angle of $\enc$ we get the entropy:
\[
    H(p) \henc
\]
while from the viewing angle of $\hash$ we get the entropy:
\[
    H(p) + \log_2 N \hhash
\]
\end{security}

so which one to pick?  i think people so far just pick $H(p) \henc$ to
reflect password's entropy, and seem to not pick $H(p) + \log_2 N \hhash$
as they don't seem to consider it entropy.  but i have two disagreements
with people:
\begin{itemize}
    \item i think not accepting that $H(p) + \log_2 N \hhash$ is entropy is
    needlessly limiting.  because i think $H(p) + \log_2 N \hhash$ is
    entropy as much as $H(p) \henc$ is entropy; it's just that they are
    measured from different viewing angles:  former is measured from the
    $\hash$ viewing angle, while the latter is measured from the $\enc$
    viewing angle.

    i don't see any reason why any of them is more true than the other.  i
    think that both of them are entropies, but of different units.

    \item why do people only pick either one of them?  it's technically
    false my view.  in my view truth is:  we're just dealing with two
    entropies measured in different units.  so i think truth is that we
    have the following number of entropy bits:
    \begin{alignat*}{2}
            & H(p)              && \henc \\
        +{} & H(p) + \log_2 N   && \hhash 
    \end{alignat*}
    which obviously looks a bit ugly, since we cannot sum them due to the
    terms having different units, which also gives our brain a hard time to
    get a feeling of what that even means.
\end{itemize}

so what's the solution here to this ugliness?  should we ignore $H(p)\henc
+ H(p)+\log_2N\hhash$ as an entropy measure that quantifies the security of
our protection against password brute-forcing, as people currently do, and
measure it only in terms of the computational cost by surveying the
industry of asics in order to find a map between
time and money?

my answer to the questions above is:  
\begin{itemize}
    \item no.  the right approach is to just admit that \emph{argon2}'s
    approach is dragging us into the situation where we end up with two
    entropies measured in different units.
    \item \emph{argon2}'s security contribution is measurable as entropy,
    except that it is ugly since it is made of two entropies in distinct
    units.  if we ignore this, we won't solve the problem, but end up
    stashing the dirts under the carpet.
    \item of course, we are always free to also survey the industry of
    asics to derive time-money maps, but this doesn't have to be our only
    approach to quantify our security gain.
\end{itemize}

\subsection{with \emph{ciphart}}
adversary evaluates keys from:
\begin{itemize}
    \item $\hat v_0 \gets \ciphart(\hat p_0, B, M, \ldots)$,
    \item $\hat v_1 \gets \ciphart(\hat p_1, B, M, \ldots)$,
    \item $\vdots$
    \item $\hat v_{2^{H(p)}-1} \gets \ciphart(\hat p_{2^{H(p)}-1}, B, M,
    \ldots)$,
\end{itemize}

mostly similar to $\argon$.  differences related to this section is that
$\ciphart$ calls $\enc$ instead of $\hash$, and specifies $B$ instead of
$N$, where $B \approx \log_2 N$.  similar exponential time penalty applies
with memory less than $M$.

\begin{security}
your protection against password brute-forcing attacks under the
\emph{ciphart} protection approach is:
\begin{align*}
        & \left(2^{H(p)} + 2^{\hat B}\right) \cost(\enc) + 2^{H(p)}
            \cost(\enc) \\
    ={} & \left(2^{H(p)} + 2^{\hat B} + 2^{H(p)}\right) \cost(\enc) \\
    ={} & \left(2\times2^{H(p)} + 2^{\hat B}\right) \cost(\enc) \\
    ={} & \left(2^{H(p) + \log_2 2} + 2^{\hat B}\right) \cost(\enc) \\
    ={} & \left(2^{H(p) + 1} + 2^{\hat B}\right) \cost(\enc)
\end{align*}
from the viewing angle of $\enc$ we get the entropy:
\[
    H(p) + 1 + \hat B \henc
\]
\end{security}

and there is no other viewing angle than $\enc$ since only $\enc$ is used!
as a result our brain can easily interpret it.  

plus, if we wish to study the industry of asics to obtain time-money maps,
our job will be much easier as we can simply look at the cost of asics that
are already implemented for $\enc$\footnote{e.g. if $\enc$ is a popular
algorithm, such as aes-256, then we can get more specific data from
manufacturers, ultimately giving us a more accurate time-money maps.  but
when $\enc$ is not popular, we may need to do rougher calculations based on
the expected asics area as done in the \emph{scrypt} paper.}.

\section{summary}

\end{document}
