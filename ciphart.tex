\documentclass[twocolumn]{article}
\usepackage[margin=.7in]{geometry}
\usepackage[showisoZ=false]{datetime2}
\usepackage{url}
\usepackage{tabularx}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\DeclareMathOperator{\enc}{enc}
\DeclareMathOperator{\maxf}{max}
\DeclareMathOperator{\len}{len}
\DeclareMathOperator{\hash}{hash}
\renewcommand{\contentsname}{content}
\makeatletter
\def\myrulefill{%
    \leavevmode\leaders\hrule%
    height .6ex width 1ex depth -0.4ex%
    \hfill\kern\z@%
}
\makeatother
\DTMsetdatestyle{iso}
\usepackage{cleveref} % must be loaded last
\begin{document}
\SetAlgorithmName{algorithm}{}{list of algorithms}
\SetInd{.15em}{1em}

\begin{center}
\Huge
\myrulefill\ ciphart \myrulefill\\
\LARGE
memory-hard key derivation \\
with easier measurable security\\
\normalsize
caveman\footnote{toraboracaveman [at] protonmail [dot] com}\\
\footnotesize
\DTMnow\\
\rule{1\columnwidth}{2pt}
\end{center}

\emph{argon2}\footnote{\url{https://github.com/P-H-C/phc-winner-argon2}} is
mostly nice, but trying to interpret its contribution to the protection
against password brute-forcing attacks remains more difficult than it
should be.  this vagueness is a problem that is not limited to
\emph{argon2}, but also shared with every other key derivation function
that i've known so far.

when one uses \emph{argon2}, his derived key will surely have superior
protection against password brute-forcing attacks, but by how much?  to
answer this, one would need to survey the industry that manufactures
application-specific integrated circuits (asics) to obtain a map between
\emph{time} and \emph{money}, in order to get an estimation on how much
would it cost the adversary to discover the password in a given time
window.

while the approach of surveying the asics industry is not wrong, it is
largely subjective, with expensive housekeeping, and practically leads the
user to rely on vague foundations to build his security on.  this vagueness
is not nice, and it would be better if we had an objective measure to
quantify the security of our memory-hard key derivation functions.

resolving this vagueness is not a mere luxury to have, but a necessity for
maximising survival, because it hinders the process of studying the
cost-value of memory-hard key derivation functions, which, effectively,
increases the risk of having a false sense of security.

so i propose \emph{ciphart} --- a memory-hard key derivation function with
a security contribution that is measured in a unit that i call
\emph{relative entropy bits}.  this unit is measured objectively and is
guaranteed to be true irrespective of whatever alien technology that the
adversary might have.

\texttt{libciphart}\footnote{\url{https://github.com/Al-Caveman/libciphart}}
is a library that implements \emph{ciphart} very closely to this paper,
without much fluff.  this should make integrating \emph{ciphart} into other
systems more convenient.

\texttt{ciphart}\footnote{\url{https://github.com/Al-Caveman/ciphart}} is
an application for encrypting and decrypting files that makes use of
\texttt{libciphart}.  this application is intended for use by end-users or
scripts, henceforth it has some fluff to treat mankind with dignity.
\vfill
\break

\tableofcontents
%\vfill
%\break

\section{ciphart}
\subsection{parameters}
\begin{tabularx}{\columnwidth}{lX}
    $\enc$ & encryption function.\\
    $\hash$ & hashing function.\\
    $p$ & password.\\
    $s$ & salt.\\
    $M$ & total memory in bytes.\\
    $L$ & number of memory lanes for concurrency.\\
    $T$ & number of tasks per lane segment.\\
    $B$ & minimum quantity of increased protection against password
            brute-forcing attacks in the unit of \emph{relative entropy
            bits}.\\
    $K$ & output key size in bytes.\\
\end{tabularx}

\subsection{internal variables}
\begin{tabularx}{\columnwidth}{lX}
    $C$         & $\gets \begin{cases}
                        64 \text{ bytes} & \text{if $\enc$ is
                                            \emph{xchacha20}}\\
                        16 \text{ bytes} & \text{if $\enc$ is \emph{aes}}\\
                        \ldots & \\
                     \end{cases}$\\
                & this to reflect the block size of the encryption
                    algorithm that implements $\enc$.\\
    $V$ & $\gets \begin{cases}
                        32 \text{ bytes} & \text{if $\enc$ is
                                            \emph{xchacha20}}\\
                        16 \text{ bytes} & \text{if $\enc$ is
                            \emph{aes-128}}\\
                        32 \text{ bytes} & \text{if $\enc$ is
                            \emph{aes-256}}\\
                        \ldots & \\
                     \end{cases}$\\
                & this is the size of the encryption key that's used to
                    solve \emph{ciphart}'s tasks.  this is different than
                    the $\enc$-independent $K$ which is
                    possibly used by other encryption algorithms in later
                    stages\footnote{at the expense of losing the meaning of
                    \emph{relative entropy bits}.}.\\
    $\hat T$    & $\gets \maxf(\lceil V C^{-1}\rceil, T)$.  this
                    is to ensure that we have enough encrypted bytes for
                    new keys.\\
    $\hat T$    & $\gets T - (T \bmod 2) + 2$.  this is to ensure that
                    there is an even number of tasks in a segment.  why?
                    because we need a buffer for storing the clear-text and
                    another for storing the output cipher-text.\\
\end{tabularx}
\begin{tabularx}{\columnwidth}{lX}
    $\hat M$    & $\gets M - (M \bmod C\hat TL) + C\hat TL$.  this is to
                    ensure that it is in multiples of $C\hat TL$.  why?  so
                    that all segments are of equal lengths in order to
                    simplify \emph{ciphart}'s logic.  e.g. it wouldn't be
                    nice if the last segments were of unequal sizes.\\
    $G$         & $\gets \hat MC^{-1}\hat T^{-1}L^{-1}$.  total number of
                    segments per lane.\\
    $\hat B$    & $\gets \maxf(\hat MC^{-1}, 2^B)$.  this is to ensure
                    that $\hat B$ is large enough to have at least one pass
                    over the $\hat M$-bytes memory.\\
    $\hat B$    & $\gets \hat B - (\hat B \bmod L\hat T) +
                    L\hat T$.  this is to reflect the reality that, with
                    \emph{ciphart}, segments must complete.  i.e. when the
                    user asks for $B$ \emph{relative entropy bits}, he gets
                    $\log_2 \hat B$ bits instead, where $\log_2\hat B \ge
                    B$.\\
    $m_i$       & $C$-bytes memory for $i^{th}$ task in the $\hat M$-bytes
                    pad.\\
    $n_l$       & $\gets lG\hat T$.  nonce variable for $l^{th}$ lane with
                    at least $64$ bits.\\
    $f$         & $\gets 0$.  a flag indicating whether the $\hat M$-bytes
                    pad is filled.\\
    $v$         & $\gets *\hash(p \mathbin\Vert s, V)$.  a pointer to the
                    first byte where $V$-bytes key is stored.\\
\end{tabularx}

\subsection{output}
\begin{tabularx}{\columnwidth}{lX}
$k$ & $K$-bytes key with an increased protection against brute-forcing
attacks by $\hat B$ \emph{relative entropy bits}.\\
\end{tabularx}

\subsection{steps}
steps of \emph{ciphart} is shown in \cref{alg_ciphart}.  this corresponds
to \emph{argon2d}.  adding a \emph{ciphart-i} variant is a trivial matter,
i just didn't do it yet because my threat model currently doesn't benefit
from a password independent variant.

\begin{algorithm}[tbh]
\While{$1$}{
    \For{$g=0, 1, \ldots, G-1$}{
        \For{$l=0, 1, \ldots, L-1$}{\label{ciphart_lanes}
            \For{$t=0, 1, \ldots, T-1$}{
                $i \gets gLT + lT + t$\;
                \uIf{$t < T - 1$}{
                    $j \gets i + 1$\;
                }\ElseIf{$t = T - 1$}{
                    $j \gets i - T + 1$\;
                }
                $m_j \gets \enc(m_i, n_l, v)$\;
                $n_l \gets n_l + 1$\;
                \uIf{$f = 0$}{
                    $v \gets m_j \bmod (gLTC + tC - V)$\;
                    \If{$v \ge gLTC - V$}{
                        $v \gets v + lTC$\;
                    }
                }\Else{
                    $v \gets m_j \bmod (GLTC - LTC + tC - V)$\;
                    \uIf{$v \ge gLTC + tC - V$}{
                        $v \gets v + LTC$\;
                    }\ElseIf{$v \ge gLTC - V$}{
                        $v \gets v + lTC$\;
                    }
                }
            }
        }
        \If{$n_1L = \hat B$}{
            $g_{\text{last}} \gets g$\;
            \textbf{go to} \cref{ciphart_out}\;
        }
    }
    $f \gets 1$\;
}
$i \gets g_{\text{last}}LT + T-1$\;
$k \gets \hash(
    m_i \mathbin\Vert m_{i+T} \mathbin\Vert m_{i+2T} \mathbin\Vert \ldots
    \mathbin\Vert m_{i+LT}, K
)$\label{ciphart_out}\;
\Return{$k$}
\caption{ciphart}
\label{alg_ciphart}
\end{algorithm}

\section{parallelism}
since iterations of the loop in \cref{ciphart_lanes} in \cref{alg_ciphart}
are fully independent of one other, they can quite happily utilise $L$ cpu
cores, specially when segment sizes, $T$, are larger.

\section{memory-hardness}
\begin{proof}
    \cref{alg_ciphart} is just a variation of \emph{argon2d}, except that
    it uses an encryption function, $\enc$, instead of a hashing functionn.
    so if \emph{argon2d} is memory-hard, then so is \emph{ciphart}.
\end{proof}

\section{security interpretation}
\section{comparison}
\section{summary}

\end{document}
