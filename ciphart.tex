\documentclass{article}
\usepackage[a4paper, total={7in, 8in}]{geometry}
\usepackage{multicol}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\DeclareMathOperator{\enc}{enc}
\DeclareMathOperator{\maxf}{max}
\DeclareMathOperator{\len}{len}
\renewcommand{\contentsname}{content}

\author{caveman}
\title{key derivation with easier measurable security}
\begin{document}
\begin{multicols}{2}
\maketitle

hi --- i propose \emph{ciphart}, a sequential memory-hard key derivation
function that has a security gain that's measurable more objectively and
more conveniently than anything in class known to date.

to nail this goal, \emph{ciphart}'s security gain is measured in the unit
of \emph{relative entropy bits}.  relative to what?  relative to the
encryption algorithm that's used later on.  therefore, this \emph{relative
entropy bits} measure is guaranteed to be true when the encryption
algorithm that's used with \emph{ciphart} is also the same one that's used
to encrypt the data afterwards.

my reference implementation is available
here\footnote{\url{https://github.com/Al-Caveman/ciphart}}.

\tableofcontents
\vfill\null
\columnbreak

\section{ciphart}
\noindent\textbf{parameters:}

\begin{tabular}{lp{18em}}
    $W$ & each task's size, at least $32$ bytes.\\
    $M$ & total memory in multiples of $2W$.\\
    $R$ & number of rounds per task.\\
    $B$ & added security in \emph{relative entropy bits}.\\
    $\enc$ & encryption function.\\
    $k$ & initial key.\\
\end{tabular}

\noindent\textbf{input:}

\begin{tabular}{lp{18em}}
    $T$ & $\gets M/W$\\
    $P$ & $\gets \maxf(2, \lceil2^B / (TR)\rceil)$\\
    $m_{l,s,t}$ & memory for $t^{th}$ task, in $s^{th}$ segment, in
    $l^{th}$ lane to work on.\\
    $n$ & $\gets 0$, a variable with enough bytes to store nonces in.
    $n[0]$ means first $64$ bits.  $n[1]$ means second $64$ bits.\\
\end{tabular}

\noindent\textbf{output:}

\begin{tabular}{lp{18em}}
$\hat k$ & better key, with $B$, or more, \emph{relative entropy bits}.\\
\end{tabular}

\begin{algorithm}[tbh]
\While{true}{
    \For{$s=1, 2, \ldots, S$}{
        \For{$l=1, 2, \ldots, L$}{
            \For{$t=1, 2, \ldots, T$}{
                \For{$r=1, 2, \ldots, R$}{
                    \eIf{$t = 1$}{
                        $m_{l,s,t} \gets \enc(m_{l,s,T}, n, k)$\;
                    }{
                        $m_{l,s,t} \gets \enc(m_{l,s,t-1}, n, k)$\;
                    }
                    $n[1] \gets n[1] + 1$\;
                    $k \gets f(m_{l,s,t}[-64:], p, l, s, t)$\;
                }
            }
        }
        \If{$\log_2\left(n[0] \times SLTR + n[1]\right) \ge B$}{
            \textbf{go to step} 15\;
        }
    }
    $n[0] \gets n[0] + 1$\;
}
\While{true}{
    $n[0] \gets n[0] + 1$\;
    \For{$l=1, 2, \ldots, L$}{
        \If{$\len(\hat k) \ge K$}{
            \Return $\hat k[0:K]$
        }
        $\hat k \gets \hat k \mathbin\Vert \enc(m_{l,S,T}[1], n, k)$\;
        $n[1] \gets n[1] + 1$\;
    }
}
\caption{ciphart version 6}
\end{algorithm}

\section{parallelism}
iterations in steps $2$ to $12$, are independent of one another, so we can
distribute them happily across different threads to achieve maximum cpu
utilisation.

iterations in steps $13$ to $18$ can also be done in parallel after
completion of steps $2$ to $12$.

\section{hardness with smaller memory}
steps $13$ to $18$ is the part where sequential memory-hardness is expected
to be born.  proof maybe soon.  but first i have to actually test it in
code to see how fast/slow is it.  right now i fear that memory's I/O might
become a significant bottleneck.
\vfill\null
\columnbreak

\section{security interpretation}
\section{comparison}
\section{summary}

\end{multicols}
\end{document}
